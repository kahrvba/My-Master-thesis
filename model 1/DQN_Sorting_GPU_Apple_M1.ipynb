{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d756dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # numerical coprations and arry handling\n",
    "import pandas as pd #manages data in dataframe format for results\n",
    "import time # meaure the exection time of sorting alogrithms\n",
    "import tensorflow as tf # core library for building abd training the DQn neural network\n",
    "from tensorflow.keras import layers # provide layers for neural network architecture\n",
    "import matplotlib.pyplot as plt #  creates plots for visualization\n",
    "import seaborn as sns # Enhanches plot aesthetics and statistical visulization\n",
    "from collections import deque # implelment double-ended queue fott the DQN's experience replay memory\n",
    "import random # Select random datasets during training and evalutions\n",
    "import os \n",
    "\n",
    "# Check for GPU availability\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"Using GPU with Metal backend (Apple Silicon)\")\n",
    "else:\n",
    "    print(\"No GPU found. Running on CPU.\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72346e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting algorithms\n",
    "def bubble_sort(arr):\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        for j in range(0, n - i - 1):\n",
    "            if arr[j] > arr[j + 1]:\n",
    "                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n",
    "    return arr\n",
    "\n",
    "def merge_sort(arr):\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    mid = len(arr) // 2\n",
    "    left = merge_sort(arr[:mid])\n",
    "    right = merge_sort(arr[mid:])\n",
    "    return merge(left, right)\n",
    "\n",
    "def merge(left, right):\n",
    "    result = []\n",
    "    i = j = 0\n",
    "    while i < len(left) and j < len(right):\n",
    "        if left[i] <= right[j]:\n",
    "            result.append(left[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            result.append(right[j])\n",
    "            j += 1\n",
    "    result.extend(left[i:])\n",
    "    result.extend(right[j:])\n",
    "    return result\n",
    "\n",
    "def quick_sort(arr):\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    pivot = arr[len(arr) // 2]\n",
    "    left = [x for x in arr if x < pivot]\n",
    "    middle = [x for x in arr if x == pivot]\n",
    "    right = [x for x in arr if x > pivot]\n",
    "    return quick_sort(left) + middle + quick_sort(right)\n",
    "\n",
    "# Utility function to measure execution time\n",
    "def measure_execution_time(algorithm, arr):\n",
    "    start_time = time.time()\n",
    "    algorithm(arr.copy())\n",
    "    return time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170136d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_inversions(arr):\n",
    "    if len(arr) <= 1:\n",
    "        return 0, arr\n",
    "    mid = len(arr) // 2\n",
    "    left_inv, left = count_inversions(arr[:mid])\n",
    "    right_inv, right = count_inversions(arr[mid:])\n",
    "    merge_inv, merged = merge_and_count(left, right)\n",
    "    return left_inv + right_inv + merge_inv, merged\n",
    "\n",
    "def merge_and_count(left, right):\n",
    "    result = []\n",
    "    i = j = inv_count = 0\n",
    "    while i < len(left) and j < len(right):\n",
    "        if left[i] <= right[j]:\n",
    "            result.append(left[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            result.append(right[j])\n",
    "            inv_count += len(left) - i\n",
    "            j += 1\n",
    "    result.extend(left[i:])\n",
    "    result.extend(right[j:])\n",
    "    return inv_count, result\n",
    "\n",
    "def get_dataset_features(arr):\n",
    "    size = len(arr)\n",
    "    if size == 0:\n",
    "        return np.zeros(6, dtype=np.float32)\n",
    "    size_normalized = size / 2000000\n",
    "    sortedness = np.sum(np.diff(arr) > 0) / (size - 1) if size > 1 else 1.0\n",
    "    inv_count, _ = count_inversions(arr)\n",
    "    max_inversions = size * (size - 1) / 2 if size > 1 else 1\n",
    "    inversions_normalized = inv_count / max_inversions\n",
    "    unique_ratio = len(np.unique(arr)) / size\n",
    "    range_val = (np.max(arr) - np.min(arr)) / 1000 if size > 0 else 0\n",
    "    clusters = len(np.unique(np.histogram(arr, bins=min(10, size//1000))[0] > 0))\n",
    "    return np.array([size_normalized, sortedness, inversions_normalized, unique_ratio, range_val, clusters], dtype=np.float32)\n",
    "\n",
    "dataset_files = []\n",
    "for folder in ['Data_set_0-63', 'Data_set_0-1000']:\n",
    "    folder_path = os.path.join(os.getcwd(), folder)\n",
    "    if os.path.exists(folder_path):\n",
    "        files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "        dataset_files.extend(files)\n",
    "    else:\n",
    "        print(f\"Warning: Folder {folder} not found in {os.getcwd()}\")\n",
    "\n",
    "if not dataset_files:\n",
    "    raise FileNotFoundError(\"No .txt files found in Data_set_0-63 or Data_set_0-1000\")\n",
    "\n",
    "random.shuffle(dataset_files)\n",
    "split_idx = int(0.8 * len(dataset_files))\n",
    "train_files = dataset_files[:split_idx]\n",
    "eval_files = dataset_files[split_idx:]\n",
    "\n",
    "print(f\"Training files: {len(train_files)}\")\n",
    "print(f\"Evaluation files: {len(eval_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877982fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute features and execution times for training files\n",
    "train_file_features = {}\n",
    "train_file_times = {algo.__name__: {} for algo in [bubble_sort, merge_sort, quick_sort]}\n",
    "for dataset_file in train_files:\n",
    "    with open(dataset_file, 'r') as f:\n",
    "        line = f.readline()\n",
    "        arr = list(map(int, line.split()))\n",
    "    train_file_features[dataset_file] = get_dataset_features(arr)\n",
    "    for algo in [bubble_sort, merge_sort, quick_sort]:\n",
    "        train_file_times[algo.__name__][dataset_file] = measure_execution_time(algo, arr)\n",
    "    print(f\"Precomputed for {os.path.basename(dataset_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0991192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=5000)\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0``\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.90  # Faster decay\n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.update_target_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Input(shape=(self.state_size,)),\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(self.action_size, activation='linear')\n",
    "        ])\n",
    "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005))\n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state, verbose=0)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        states = np.array([t[0][0] for t in minibatch])\n",
    "        actions = np.array([t[1] for t in minibatch])\n",
    "        rewards = np.array([t[2] for t in minibatch])\n",
    "        next_states = np.array([t[3][0] for t in minibatch])\n",
    "        dones = np.array([t[4] for t in minibatch])\n",
    "\n",
    "        targets = self.model.predict(states, verbose=0)\n",
    "        targets_next = self.target_model.predict(next_states, verbose=0)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            targets[i][actions[i]] = rewards[i] if dones[i] else rewards[i] + self.gamma * np.amax(targets_next[i])\n",
    "\n",
    "        self.model.fit(states, targets, epochs=1, verbose=0)\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d40c182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(episodes, batch_size=32):\n",
    "    state_size = 6\n",
    "    action_size = 3\n",
    "    agent = DQNAgent(state_size, action_size)\n",
    "    algorithms = [bubble_sort, merge_sort, quick_sort]\n",
    "    algo_names = ['Bubble Sort', 'Merge Sort', 'Quick Sort']\n",
    "    results = []\n",
    "\n",
    "    files_per_epoch = len(train_files)\n",
    "    for episode in range(episodes):\n",
    "        if episode % files_per_epoch == 0:\n",
    "            random.shuffle(train_files)\n",
    "        file_idx = episode % files_per_epoch\n",
    "        dataset_file = train_files[file_idx]\n",
    "        \n",
    "        state = train_file_features[dataset_file].reshape(1, state_size)\n",
    "        exec_times = [train_file_times[algo.__name__][dataset_file] for algo in algorithms]\n",
    "        best_algo_idx = np.argmin(exec_times)\n",
    "        action = agent.act(state)\n",
    "        best_time = exec_times[best_algo_idx] if exec_times[best_algo_idx] > 0 else 1e-6\n",
    "        reward = -(exec_times[action] / best_time)\n",
    "        reward = np.clip(reward, -10, 0)\n",
    "        next_state = state\n",
    "        done = True\n",
    "\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)\n",
    "\n",
    "        if episode % 5 == 0:\n",
    "            agent.update_target_model()\n",
    "            if gpus:\n",
    "                gpu_memory = tf.config.experimental.get_memory_info('GPU:0')\n",
    "                print(f\"Episode {episode}, GPU Memory Used: {gpu_memory['current'] / 1024**2:.2f} MB, Peak: {gpu_memory['peak'] / 1024**2:.2f} MB\")\n",
    "\n",
    "        folder = 'Data_set_0-63' if 'Data_set_0-63' in dataset_file else 'Data_set_0-1000'\n",
    "        results.append({\n",
    "            'Episode': episode,\n",
    "            'Dataset File': dataset_file,\n",
    "            'Folder': folder,\n",
    "            'Predicted Algorithm': algo_names[action],\n",
    "            'Actual Best': algo_names[best_algo_idx],\n",
    "            'Execution Time': exec_times[action],\n",
    "            'Best Execution Time': exec_times[best_algo_idx]\n",
    "        })\n",
    "        print(f\"Episode {episode}/{episodes}, File: {os.path.basename(dataset_file)}, Predicted: {algo_names[action]}, Best: {algo_names[best_algo_idx]}\")\n",
    "\n",
    "    agent.save('dqn_sorting_model_refined.weights.h5')\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efb15b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "    state_size = 6\n",
    "    action_size = 3\n",
    "    agent = DQNAgent(state_size, action_size)\n",
    "    agent.load('dqn_sorting_model_refined.weights.h5')\n",
    "    algorithms = [bubble_sort, merge_sort, quick_sort]\n",
    "    algo_names = ['Bubble Sort', 'Merge Sort', 'Quick Sort']\n",
    "    results = []\n",
    "\n",
    "    for i, dataset_file in enumerate(eval_files):\n",
    "        with open(dataset_file, 'r') as f:\n",
    "            line = f.readline()\n",
    "            arr = list(map(int, line.split()))\n",
    "        state = get_dataset_features(arr).reshape(1, state_size)\n",
    "        action = agent.act(state)\n",
    "        exec_times = [measure_execution_time(algo, arr) for algo in algorithms]\n",
    "        best_algo_idx = np.argmin(exec_times)\n",
    "        folder = 'Data_set_0-63' if 'Data_set_0-63' in dataset_file else 'Data_set_0-1000'\n",
    "        results.append({\n",
    "            'Test Index': i,\n",
    "            'Dataset File': dataset_file,\n",
    "            'Folder': folder,\n",
    "            'Predicted Algorithm': algo_names[action],\n",
    "            'Actual Best': algo_names[best_algo_idx],\n",
    "            'Execution Time': exec_times[action],\n",
    "            'Best Execution Time': exec_times[best_algo_idx],\n",
    "            'Correct': algo_names[action] == algo_names[best_algo_idx]\n",
    "        })\n",
    "        print(f\"Evaluation {i+1}/{len(eval_files)}, File: {os.path.basename(dataset_file)}, Predicted: {algo_names[action]}, Best: {algo_names[best_algo_idx]}\")\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b37ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(df_train, df_test):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Training plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(df_train['Episode'], df_train['Execution Time'], label='Predicted')\n",
    "    plt.plot(df_train['Episode'], df_train['Best Execution Time'], label='Best')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Execution Time (s)')\n",
    "    plt.title('Training: Predicted vs Best Execution Time')\n",
    "    plt.legend()\n",
    "\n",
    "    # Test accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    accuracy = df_test['Correct'].mean() * 100\n",
    "    plt.bar(['Accuracy'], [accuracy])\n",
    "    plt.ylim(0, 100)\n",
    "    plt.title(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_progress.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735be491",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 1000\n",
    "df_train = train_dqn(episodes)\n",
    "df_train.to_csv('training_results.csv', index=False)\n",
    "df_test = evaluate_model()\n",
    "df_test.to_csv('test_results.csv', index=False)\n",
    "plot_results(df_train, df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
